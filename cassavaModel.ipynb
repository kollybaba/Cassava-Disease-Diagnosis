import pandas as pd
import numpy as np
import keras
import cv2
import matplotlib.pyplot as plt
import os
from glob import glob
from tqdm import tqdm
from keras.applications import mobilenet_v2, resnet50, VGG16, MobileNetV2

os.listdir("../input/")

path = "../input/cropped-cassava-images/cropped cbb/"
img_sample = os.listdir(os.path.join(path,'cropped cbb'))[0]
img_sample

img = cv2.imread(os.path.join("../input/cropped-cassava-images/cropped cbb/cropped cbb", img_sample))
print(img.shape)
plt.imshow(img)

path = "../input/cropped-cassava-images/"

def pull_to_dataframe(path):
    path = "../input/cropped-cassava-images/"
    df = pd.DataFrame(columns=['Filename', 'Label'])
    label_dictionary = {'cropped healthy':0, 'cropped cbb':1, 'cropped cgm':2, 'cropped cmd':3, 'cropped cbsd':4}
    filenames = []
    labels = []
    
    for c in os.listdir(path):
        if c!='cropped test':
            label = label_dictionary[c]
            new_path = os.path.join(path,c)
            class_path = os.path.join(new_path,c)
            finder = 'cropped-cassava-images'
            for file in tqdm(glob(os.path.join(class_path, '*.PNG'))):
                index = file.find(finder)
                filename = file[index:]
                filenames.append(filename)
                labels.append(label)
    print (c,path,new_path, class_path)
    df['Filename'] = filenames
    df['Label'] = labels
    return df, label_dictionary
    
    df_data = pull_to_dataframe(path)
    
    df, label_dict = df_data
    
    from keras.preprocessing.image import ImageDataGenerator
    
    # image_gen = ImageDataGenerator(zoom_range=0.2,rescale=1./255,zca_whitening=0.1, featurewise_center=True, 
#                                horizontal_flip=True, vertical_flip=True, shear_range=0.2)

image_gen = ImageDataGenerator(rescale=1./255)

from sklearn.utils import shuffle
df = shuffle(df)
df.head()

df.Label = df.Label.astype('str')

train_number = 4000
val_stop = 5000
train_df = df[:train_number]
val_df = df[train_number:val_stop]
test_df = df[val_stop:]
batch_size =32
train_gen = image_gen.flow_from_dataframe(dataframe=train_df,x_col='Filename', 
                                          directory='../input/',
                                          y_col='Label', shuffle=True,batch_size=batch_size, 
                                          target_size=(224,224))
                                          
                                          val_batch_size = 64
test_batch_size=1
val_gen = image_gen.flow_from_dataframe(dataframe=val_df,x_col='Filename', 
                                        directory='../input/',
                                          y_col='Label', shuffle=True,batch_size=val_batch_size, 
                                        target_size=(224,224))
                                        
           test_gen = ImageDataGenerator()
test_generator = test_gen.flow_from_dataframe(dataframe=test_df,x_col='Filename', 
                                         directory='../input/',
                                          y_col='Label', shuffle=True,batch_size=test_batch_size, target_size=(224,224))
                                          
base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224,224,3))

from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPool2D
from keras import Sequential
from keras.optimizers import Nadam, RMSprop, Adam
from keras import layers
from keras.layers import GlobalAveragePooling2D 
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

first_filter = 16
second_filter = 32
third_filter = 64
pool_size=(2,2)

model = Sequential()
model.add(base)
model.add(layers.GlobalAvgPool2D())
model.add(Dense(512, activation='relu'))
model.add(Dense(5, activation='softmax'))
model.summary()

model.summary()

checkpoint = ModelCheckpoint("model.h5", save_best_only=True)
reduce =  ReduceLROnPlateau(patience=2, factor=0.1,verbose=2)
stopper = EarlyStopping(patience=5, verbose=2)
nadam =  Nadam(lr=0.1)
rms = RMSprop()
adam = Adam()

model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])

model.fit_generator(train_gen,steps_per_epoch=train_df.shape[0]//batch_size, 
                    validation_data=val_gen, validation_steps=val_df.shape[0]//val_batch_size, epochs=20, 
                    workers=-1, callbacks=[checkpoint, reduce, stopper])

history = model.history.history
plt.plot(model.history.epoch, history['acc'],label='training_acc')
plt.plot(model.history.epoch, history['val_acc'],c='green', label='Validation Accuracy')
plt.xlabel('Epochs')
plt.legend()

plt.plot(model.history.epoch, history['loss'],label='training_loss')
plt.plot(model.history.epoch, history['val_loss'],c='green', label='Validation Loss')
plt.xlabel('Epochs')
plt.legend()

from keras.models import load_model 
predictor = load_model('model.h5', compile=False)
test_generator = image_gen.flow_from_dataframe(dataframe=test_df,x_col='Filename', 
                                         directory='../input/',
                                          y_col='Label', shuffle=False,batch_size=test_batch_size, target_size=(224,224))
no_of_samples = test_df.shape[0]
results = model.evaluate_generator(test_generator, steps=no_of_samples//test_batch_size)
loss, accuracy = results
print("ACCURACY OF OVERALL PREDICTIONS: ", accuracy)

predictions = model.predict_generator(test_generator,steps=no_of_samples//test_batch_size)

test_generator2 = image_gen.flow_from_dataframe(dataframe=sorttest,x_col='Filename', 
                                         directory='../input/',
                                          y_col='Label', shuffle=False,batch_size=test_batch_size, target_size=(224,224))
sorttest = test_df.sort_index()
predictions2 = model.predict_generator(test_generator,steps=no_of_samples//test_batch_size)

from keras.preprocessing.image import load_img, img_to_array
shuffle(test_df).head()

def get_prediction(row):
    """RETURNS ORIGINAL WORDED LABEL AND PREDICTIONS"""
    rev_dictionary = {0: 'Healthy', 1: 'Cbb', 2: 'Cgm', 3:'Cmd', 4:'Cbsd'}
    filename = row['Filename']
    
    fpath = os.path.join('../input', filename)

    im = load_img(fpath, filename)
    im = img_to_array(im)
    im = im/255
    im = cv2.resize(im, (224,224))
    im = np.expand_dims(im, axis=0)
    p = model.predict(im)
    p = p.argmax(axis=1)[0]
    prediction = rev_dictionary.get(p)
    return prediction

def get_label(row):
    rev_dictionary = {0: 'Healthy', 1: 'Cbb', 2: 'Cgm', 3:'Cmd', 4:'Cbsd'}
    label = int(row['Label'])
    return rev_dictionary.get(label)
    
    tcopy = test_df.copy()
tcopy['Disease'] = test_df.apply(get_label, axis=1)
tcopy['Prediction'] = test_df.apply(get_prediction, axis=1)

tcopy.to_csv("500_TEST_SAMPLE_PREDICTIONS(unseen_data).csv", index=False)
os.listdir()
